{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficient Simulation in the Inventory Model\n",
    "\n",
    "\n",
    "#### John Stachurski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation can be time consuming, especially if we need to simulate many paths\n",
    "\n",
    "And it's often true that large sample sizes are necessary to get an accurate picture\n",
    "\n",
    "Let's look at speeding up our simulations using [Numba](https://numba.pydata.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit, njit, prange\n",
    "from quantecon.util import tic, toc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, S = 10, 100\n",
    "p = 0.4\n",
    "initial_x = 50.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating One Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at simulating one path with minimal optimization.\n",
    "\n",
    "(There's at least some efficiency gain over pure Python because we'll use a vectorized function to generate the random variables.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_one_inventory_path(sim_length=10_000_000):\n",
    "        \n",
    "    dvals = np.random.geometric(p, size=sim_length-1) - 1\n",
    "    X = np.empty(sim_length, dtype=np.int64)\n",
    "    X[0] = initial_x\n",
    "    \n",
    "    for t, d in enumerate(dvals):\n",
    "        x = X[t]\n",
    "        if x <= s:\n",
    "            X[t+1] = max(S - d, 0)\n",
    "        else:\n",
    "            X[t+1] = max(x - d, 0)\n",
    "            \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How fast does this run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOC: Elapsed: 0:00:8.78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.788817882537842"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic()\n",
    "X = sim_one_inventory_path()\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build a jitted version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def update(x):        \n",
    "    d = np.random.geometric(p) - 1\n",
    "    if x <= s:\n",
    "        y = np.maximum(S - d, 0)\n",
    "    else:\n",
    "        y = np.maximum(x - d, 0)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def sim_one_path_jitted(sim_length=10_000_000):\n",
    "    X = np.empty(sim_length, dtype=np.int64)\n",
    "    X[0] = initial_x\n",
    "    for t in range(sim_length-1):\n",
    "        X[t+1] = update(X[t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is **much** faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOC: Elapsed: 0:00:0.44\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4414072036743164"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic()\n",
    "X = sim_one_path_jitted()\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Calculate Stationary Order Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've seen, the inventory model has a stationary distribution.\n",
    "\n",
    "Let's call it $\\psi^*$, with the corresponding random variable denoted $X^*$.\n",
    "\n",
    "For a large population with independent demand shocks,\n",
    "\n",
    "$$ \\mathbb P\\{X^* = k\\} \\simeq \\text{fraction of firms with inventory } k $$\n",
    "\n",
    "We are interested in calculating\n",
    "\n",
    "$$ \\mathbb P\\{X^* \\leq s\\} \\simeq \\text{fraction of firms currently placing orders } $$\n",
    "\n",
    "The law of large numbers for stationary and ergodic sequences tells us that\n",
    "\n",
    "$$ \\mathbb P\\{X^* \\leq s\\} \\simeq \\frac{1}{n} \\sum_{t=1}^n \\mathbb 1\\{X_t \\leq s\\} $$\n",
    "\n",
    "In other words, we can calculate the stationary probability $\\mathbb P\\{X^* \\leq s\\}$ by generating a single time series and calculating the fraction of time that it spends below $s$.\n",
    "\n",
    "We can do this fast with the jitted code above, thanks to Numba.\n",
    "\n",
    "#### Exploiting parallelization\n",
    "\n",
    "However, the above approach is difficult to parallelize because it's inherently sequential\n",
    "\n",
    "An approach that's easier to parallelize is to \n",
    "\n",
    "* pick some large value $T$\n",
    "\n",
    "* generate many independent observations $X^i_T$ of $X_T$\n",
    "\n",
    "* calculate the fraction of observations that are less than $s$\n",
    "\n",
    "This works because \n",
    "\n",
    "$$ \\mathbb P\\{X^* \\leq s\\} \\simeq \\mathbb P \\{X_T \\leq s\\} $$\n",
    "\n",
    "when $T$ is large (since, as previously discussed, $\\psi_t \\to \\psi^*$).\n",
    "\n",
    "Thus, letting $m$ be the number of paths we'll generate, our goal is to fix large $T$ and compute\n",
    "\n",
    "$$ p(m, T) = \\frac{1}{m} \\sum_{i=1}^m \\mathbb 1\\{X_T^i \\leq s\\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating Many Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a jitted (and hence fast) piece of code for simulating many paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def sim_prob(m=500_000, T=1000):\n",
    "    \n",
    "    is_below_s = 0\n",
    "    for i in range(m):\n",
    "        x = initial_x\n",
    "        for t in range(T):\n",
    "            x = update(x)\n",
    "        if x <= s:\n",
    "            is_below_s += 1\n",
    "    p_m_T = is_below_s / m\n",
    "    return p_m_T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a reading on the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOC: Elapsed: 0:00:20.78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.7879695892334"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic()\n",
    "p = sim_prob()\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016094"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try a simple parallelization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def sim_prob_parallel(m=500_000, T=1000):\n",
    "    \n",
    "    is_below_s = 0\n",
    "    for i in prange(m):\n",
    "        x = initial_x\n",
    "        for t in range(T):\n",
    "            x = update(x)\n",
    "        if x <= s:\n",
    "            is_below_s += 1\n",
    "    p_m_T = is_below_s / m\n",
    "    return p_m_T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOC: Elapsed: 0:00:4.26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.2602362632751465"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic()\n",
    "p = sim_prob_parallel()\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016428"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try for a more efficient parallelization, where the work is divided into a smaller number of chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def sim_prob_parallel(m=500_000, T=1000, chunks=500):\n",
    "    \n",
    "    chunk_size = m // chunks\n",
    "    p_m_T_vals = np.empty(chunks)\n",
    "    \n",
    "    for i in prange(chunks):\n",
    "        p_m_T_vals[i] = sim_prob(m=chunk_size)\n",
    "\n",
    "    return p_m_T_vals.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the speed up from parallelization is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOC: Elapsed: 0:00:4.35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.351317644119263"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic()\n",
    "X = sim_prob_parallel()\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's essentially no difference --- so `prange` is already optimizing the load across CPUs for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
